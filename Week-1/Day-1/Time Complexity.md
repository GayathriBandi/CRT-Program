## ğŸ“˜ Day 1: Time Complexity

Welcome to **Day 1** of my DSA Learning Journey!  
Todayâ€™s focus: **Time Complexity** â€“ a fundamental concept to evaluate how efficiently an algorithm performs as input size grows.

---

## ğŸ§  What is Time Complexity?

Time Complexity refers to how the runtime of an algorithm scales with the input size `n`.  
It is expressed using **Big O Notation** and helps compare algorithm efficiency.

### ğŸ”¢ Common Notations

- `O(1)` â€“ Constant Time  
- `O(n)` â€“ Linear Time  
- `O(log n)` â€“ Logarithmic Time  
- `O(n log n)` â€“ Linearithmic Time  
- `O(nÂ²)` â€“ Quadratic Time  
- `O(2â¿)` â€“ Exponential Time  
- `O(n!)` â€“ Factorial Time  

---

### âœ¨ Why It's Important

- ğŸ” **Compare** algorithm efficiency  
- âš™ï¸ **Optimize** performance  
- ğŸ“ˆ **Predict** scalability  

---

## ğŸ“Š Common Time Complexities

| Big O        | Name         | Description                             | Example                    |
|--------------|--------------|-----------------------------------------|----------------------------|
| `O(1)`       | Constant      | Executes in the same time always        | Access `arr[0]`            |
| `O(log n)`   | Logarithmic   | Halves the input each step              | Binary Search              |
| `O(n)`       | Linear        | Proportional to input size              | Loop through array         |
| `O(n log n)` | Linearithmic  | Log factor on top of linear             | Merge Sort, Quick Sort     |
| `O(nÂ²)`      | Quadratic     | Nested loops                            | Bubble Sort                |
| `O(2â¿)`      | Exponential   | Doubles with each additional input      | Recursive Fibonacci        |
| `O(n!)`      | Factorial     | All permutations                        | Traveling Salesman Problem |

---

## ğŸ›ï¸ Rahul at the Shopping Mall (Analogy)

- ğŸŸ¢ **O(1)** â€“ Rahul walks into the first store and buys a T-shirt.  
- ğŸ”µ **O(n)** â€“ He visits every store before picking one.  
- ğŸŸ¡ **O(log n)** â€“ Uses a sorted mall directory and eliminates half the stores each time.  
- ğŸ”´ **O(nÂ²)** â€“ Compares every T-shirt in every store with all others. Way too slow!

---

## ğŸ’» Code Examples in C

### ğŸ”¹ O(1) â€“ Constant Time

### ğŸ”¹ O(1) â€“ Constant Time
```c
#include <stdio.h>
int getFirst(int arr[]) {
    return arr[0];
}
int main() {
    int arr[] = {10, 20, 30, 40};
    printf("First element: %d\n", getFirst(arr));
    return 0;
}

ğŸ”¹ O(n) â€“ Linear Time

#include <stdio.h>
void printAll(int arr[], int size) {
    for(int i = 0; i < size; i++) {
        printf("%d\n", arr[i]);
    }
}
int main() {
    int arr[] = {10, 20, 30, 40, 50};
    int size = sizeof(arr) / sizeof(arr[0]);
    printAll(arr, size);
    return 0;
}

ğŸ”¹ O(log n) â€“ Logarithmic Time (Binary Search)

#include <stdio.h>
int binarySearch(int arr[], int size, int key) {
    int low = 0, high = size - 1;
    while (low <= high) {
        int mid = (low + high) / 2;
        if (arr[mid] == key)
            return mid;
        else if (arr[mid] < key)
            low = mid + 1;
        else
            high = mid - 1;
    }
    return -1;
}
int main() {
    int arr[] = {2, 4, 6, 8, 10, 12, 14};
    int size = sizeof(arr) / sizeof(arr[0]);
    int key = 10;
    int result = binarySearch(arr, size, key);
    if (result != -1)
        printf("Element found at index %d\n", result);
    else
        printf("Element not found\n");
    return 0;
}

ğŸ”¹ O(nÂ²) â€“ Quadratic Time

#include <stdio.h>
void allPairs(int arr[], int size) {
    for(int i = 0; i < size; i++) {
        for(int j = 0; j < size; j++) {
            printf("(%d, %d)\n", arr[i], arr[j]);
        }
    }
}
int main() {
    int arr[] = {1, 2, 3};
    int size = sizeof(arr) / sizeof(arr[0]);
    allPairs(arr, size);
    return 0;
}
 ğŸ§© Tips to Improve Time Complexity
 âœ… Use hash maps or sets for faster lookups

 ğŸ” Eliminate unnecessary nested loops

 ğŸ” Prefer binary search for sorted data

âš™ï¸ Choose efficient algorithms (e.g., Merge Sort over Bubble Sort)

ğŸ§  Time vs Space: Simplified
ğŸ’¡ Definitions
Time Complexity â†’ How long your code takes to run

Space Complexity â†’ How much memory your code uses

ğŸšŒ Story: Waiting for a Bus
Imagine you're waiting for a specific bus. Your approach shows different complexities:

ğŸ”´ O(nÂ²) â€“ Confused Passenger:
Asks everyone about every bus. Very inefficient.

ğŸŸ¢ O(n) â€“ Careful Observer:
Checks each bus as it comes. Simple and practical.

ğŸŸ¢ O(log n) â€“ Smart Commuter:
Uses a bus tracking app. Skips irrelevant ones. Very efficient.

ğŸ“‹ Comparison Table
Scenario	Time	Space	Technique Used
Brute-force search	O(nÂ²)	O(1)	Nested loops
Hash map for lookups	O(n)	O(n)	Dictionary / Set
Dynamic Programming (Memo)	O(n)	O(n)	Memoization table

âœ… Final Thoughts
Focus on writing algorithms with better time complexity

Remember: faster code may use more memory (a space-time tradeoff)

Balance both based on constraints

Think like Rahul or the Smart Commuter, not the confused passenger ğŸ˜‰

yaml
Copy
Edit

---

Let me know if you'd like:
- A downloadable `.md` file  
- A visual diagram or infographic to embed  
- Or to format it for a GitHub Pages website!


